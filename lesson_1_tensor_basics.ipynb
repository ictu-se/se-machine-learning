{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d2a7ded",
   "metadata": {},
   "source": [
    "# üìò Lesson 1: Tensors - The Building Blocks of Machine Learning\n",
    "\n",
    "---\n",
    "\n",
    "### üéØ Why this lesson is important\n",
    "Machine Learning is about teaching computers to **learn from data**.  \n",
    "But all data ‚Äî text, images, sound, video ‚Äî must first be represented as **numbers**.  \n",
    "\n",
    "A **Tensor** is the universal way to store and manipulate these numbers.  \n",
    "If you understand Tensors, you understand the \"language\" that ML models speak.  \n",
    "\n",
    "In this lesson, we will not only learn *how* to use Tensors in PyTorch,  \n",
    "but also *why each operation is important for ML*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22e9b618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import torch\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e78086",
   "metadata": {},
   "source": [
    "## üîç Part 1: What is a Tensor?\n",
    "\n",
    "- A Tensor is just a **multi-dimensional array** (like a list, but more powerful).  \n",
    "- Why not just use Python lists?  \n",
    "  - Lists are **slow** and cannot run on GPU.  \n",
    "  - ML requires **millions of operations per second** ‚Äî Tensors make this possible.  \n",
    "\n",
    "üí° **In ML context**:  \n",
    "- An image (28√ó28 grayscale) is stored as a **2D tensor**.  \n",
    "- A color image (32√ó32√ó3) is a **3D tensor**.  \n",
    "- A batch of 100 images is a **4D tensor**.  \n",
    "\n",
    "So every time we talk about data in ML, we talk about **Tensors**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3feebc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python list: [1, 2, 3, 4]\n",
      "PyTorch tensor: tensor([1, 2, 3, 4])\n",
      "Type of list: <class 'list'>\n",
      "Type of tensor: <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "# Compare Python list vs PyTorch tensor\n",
    "python_list = [1, 2, 3, 4]\n",
    "tensor = torch.tensor([1, 2, 3, 4])\n",
    "\n",
    "print(\"Python list:\", python_list)\n",
    "print(\"PyTorch tensor:\", tensor)\n",
    "print(\"Type of list:\", type(python_list))\n",
    "print(\"Type of tensor:\", type(tensor))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e4ed74",
   "metadata": {},
   "source": [
    "## üîß Part 2: Creating Tensors\n",
    "\n",
    "Why so many ways to create tensors?  \n",
    "Because data in ML comes from many sources:\n",
    "- Raw numbers (Python list)\n",
    "- Data science pipelines (NumPy arrays)\n",
    "- Empty containers to be filled (zeros, ones)\n",
    "- Random values for model initialization\n",
    "\n",
    "üí° **In ML context**:  \n",
    "When training a neural network, weights are usually **randomly initialized**.  \n",
    "Zeros/ones tensors are used as placeholders or masks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d435b74b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From list: tensor([1, 2, 3, 4, 5])\n",
      "From NumPy: tensor([1, 2, 3, 4, 5])\n",
      "Zeros (3x4):\n",
      " tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n",
      "Ones (2x3):\n",
      " tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "Random (2x3):\n",
      " tensor([[-1.0658, -0.6084,  0.2289],\n",
      "        [ 1.2029,  0.7661,  1.2428]])\n",
      "Range tensor: tensor([0, 2, 4, 6, 8])\n"
     ]
    }
   ],
   "source": [
    "# From Python list\n",
    "tensor_from_list = torch.tensor([1, 2, 3, 4, 5])\n",
    "print(\"From list:\", tensor_from_list)\n",
    "\n",
    "# From NumPy array\n",
    "numpy_array = np.array([1, 2, 3, 4, 5])\n",
    "tensor_from_numpy = torch.from_numpy(numpy_array)\n",
    "print(\"From NumPy:\", tensor_from_numpy)\n",
    "\n",
    "# Zeros\n",
    "zeros_tensor = torch.zeros(3, 4)\n",
    "print(\"Zeros (3x4):\\n\", zeros_tensor)\n",
    "\n",
    "# Ones\n",
    "ones_tensor = torch.ones(2, 3)\n",
    "print(\"Ones (2x3):\\n\", ones_tensor)\n",
    "\n",
    "# Random values\n",
    "random_tensor = torch.randn(2, 3)\n",
    "print(\"Random (2x3):\\n\", random_tensor)\n",
    "\n",
    "# Range\n",
    "range_tensor = torch.arange(0, 10, 2)\n",
    "print(\"Range tensor:\", range_tensor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eda45c7",
   "metadata": {},
   "source": [
    "## üìä Part 3: Tensor Attributes\n",
    "\n",
    "We always need to know:\n",
    "- **Shape** ‚Üí what kind of data are we holding?  \n",
    "- **Dimensions** ‚Üí is it a vector (1D), matrix (2D), image (3D), or batch (4D)?  \n",
    "- **Data type (dtype)** ‚Üí integers (labels) vs floats (features).  \n",
    "- **Device** ‚Üí CPU for preparation, GPU for training.  \n",
    "\n",
    "üí° **In ML context**:  \n",
    "- Shape mismatches cause errors in training.  \n",
    "- GPU usage makes training 100√ó faster.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54f488ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: torch.Size([3, 4, 5])\n",
      "Size (same): torch.Size([3, 4, 5])\n",
      "Dimensions: 3\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Number of elements: 60\n"
     ]
    }
   ],
   "source": [
    "sample_tensor = torch.randn(3, 4, 5)\n",
    "\n",
    "print(\"Shape:\", sample_tensor.shape)\n",
    "print(\"Size (same):\", sample_tensor.size())\n",
    "print(\"Dimensions:\", sample_tensor.dim())\n",
    "print(\"Data type:\", sample_tensor.dtype)\n",
    "print(\"Device:\", sample_tensor.device)\n",
    "print(\"Number of elements:\", sample_tensor.numel())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1f9312",
   "metadata": {},
   "source": [
    "## üéØ Part 4: Indexing and Slicing\n",
    "\n",
    "Why do we need slicing?  \n",
    "Because ML is about working with parts of data:  \n",
    "- Extracting a row of pixels from an image  \n",
    "- Taking a single word embedding from a sentence  \n",
    "- Splitting a dataset into smaller batches  \n",
    "\n",
    "Without slicing, we can‚Äôt ‚Äúlook inside‚Äù our tensors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2f3b1e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix:\n",
      " tensor([[ 1,  2,  3,  4],\n",
      "        [ 5,  6,  7,  8],\n",
      "        [ 9, 10, 11, 12]])\n",
      "Element [0,0]: tensor(1)\n",
      "Element [1,2]: tensor(7)\n",
      "First row: tensor([1, 2, 3, 4])\n",
      "First column: tensor([1, 5, 9])\n",
      "Sub-matrix:\n",
      " tensor([[2, 3],\n",
      "        [6, 7]])\n"
     ]
    }
   ],
   "source": [
    "matrix = torch.tensor([[1, 2, 3, 4],\n",
    "                       [5, 6, 7, 8], \n",
    "                       [9, 10, 11, 12]])\n",
    "print(\"Matrix:\\n\", matrix)\n",
    "\n",
    "# Indexing\n",
    "print(\"Element [0,0]:\", matrix[0,0])\n",
    "print(\"Element [1,2]:\", matrix[1,2])\n",
    "\n",
    "# Slicing\n",
    "print(\"First row:\", matrix[0, :])\n",
    "print(\"First column:\", matrix[:, 0])\n",
    "print(\"Sub-matrix:\\n\", matrix[0:2, 1:3])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa430e4",
   "metadata": {},
   "source": [
    "## üßÆ Part 5: Basic Operations\n",
    "\n",
    "ML models learn by doing **millions of arithmetic operations**:\n",
    "- Adding bias  \n",
    "- Multiplying weights  \n",
    "- Dividing by normalization factors  \n",
    "- Raising numbers to powers (activation functions like ReLU or softmax use these)  \n",
    "\n",
    "üí° Example:  \n",
    "When you scale your data from 0‚Äì255 (pixels) to 0‚Äì1, you are doing division on tensors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89b6d6aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a + b = tensor([ 6,  8, 10, 12])\n",
      "a * b = tensor([ 5, 12, 21, 32])\n",
      "b / a = tensor([5.0000, 3.0000, 2.3333, 2.0000])\n",
      "a squared = tensor([ 1,  4,  9, 16])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([1, 2, 3, 4])\n",
    "b = torch.tensor([5, 6, 7, 8])\n",
    "\n",
    "print(\"a + b =\", a + b)\n",
    "print(\"a * b =\", a * b)\n",
    "print(\"b / a =\", b / a)\n",
    "print(\"a squared =\", a ** 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75742f47",
   "metadata": {},
   "source": [
    "## üî¢ Part 6: Matrix Operations\n",
    "\n",
    "This is the **heart of Machine Learning**.  \n",
    "Why?\n",
    "- A neural network layer = **Matrix Multiplication**  \n",
    "  - Input (data) √ó Weights (parameters) = Output (features)  \n",
    "\n",
    "Transpose, sum, mean ‚Üí used in:  \n",
    "- Loss functions  \n",
    "- Feature extraction  \n",
    "- Statistics on data  \n",
    "\n",
    "If you understand matrix multiplication, you understand 80% of deep learning math.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d411295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A:\n",
      " tensor([[1., 2.],\n",
      "        [3., 4.]])\n",
      "B:\n",
      " tensor([[5., 6.],\n",
      "        [7., 8.]])\n",
      "A @ B:\n",
      " tensor([[19., 22.],\n",
      "        [43., 50.]])\n",
      "Transpose of A:\n",
      " tensor([[1., 3.],\n",
      "        [2., 4.]])\n",
      "Sum of A: tensor(10.)\n",
      "Mean of A: tensor(2.5000)\n",
      "Max of A: tensor(4.)\n",
      "Min of A: tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "matrix_a = torch.tensor([[1, 2],\n",
    "                         [3, 4]], dtype=torch.float)\n",
    "matrix_b = torch.tensor([[5, 6],\n",
    "                         [7, 8]], dtype=torch.float)\n",
    "\n",
    "print(\"A:\\n\", matrix_a)\n",
    "print(\"B:\\n\", matrix_b)\n",
    "\n",
    "print(\"A @ B:\\n\", torch.matmul(matrix_a, matrix_b))\n",
    "print(\"Transpose of A:\\n\", matrix_a.T)\n",
    "print(\"Sum of A:\", matrix_a.sum())\n",
    "print(\"Mean of A:\", matrix_a.mean())\n",
    "print(\"Max of A:\", matrix_a.max())\n",
    "print(\"Min of A:\", matrix_a.min())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0c592d",
   "metadata": {},
   "source": [
    "## üîÑ Part 7: Reshape\n",
    "\n",
    "Why reshape?  \n",
    "Because ML requires data in specific formats:\n",
    "- Images: (Batch, Channels, Height, Width)  \n",
    "- Text: (Batch, Sequence_length, Embedding_size)  \n",
    "\n",
    "Reshaping is how we ‚Äútell PyTorch‚Äù what our data looks like.  \n",
    "Example: turning 784 pixels into a flat vector for feeding into a neural network.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b12f30d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])\n",
      "Reshaped (3x4):\n",
      " tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11]])\n",
      "Reshaped (2x2x3):\n",
      " tensor([[[ 0,  1,  2],\n",
      "         [ 3,  4,  5]],\n",
      "\n",
      "        [[ 6,  7,  8],\n",
      "         [ 9, 10, 11]]])\n",
      "Flattened: tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])\n"
     ]
    }
   ],
   "source": [
    "original = torch.arange(12)\n",
    "print(\"Original:\", original)\n",
    "\n",
    "reshaped_2d = original.reshape(3, 4)\n",
    "print(\"Reshaped (3x4):\\n\", reshaped_2d)\n",
    "\n",
    "reshaped_3d = original.reshape(2, 2, 3)\n",
    "print(\"Reshaped (2x2x3):\\n\", reshaped_3d)\n",
    "\n",
    "flattened = reshaped_2d.flatten()\n",
    "print(\"Flattened:\", flattened)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357c1155",
   "metadata": {},
   "source": [
    "## üì° Part 8: Broadcasting\n",
    "\n",
    "Broadcasting = making different-sized tensors work together.  \n",
    "\n",
    "Why important?  \n",
    "- Adding a bias vector to every row of a dataset  \n",
    "- Normalizing images by subtracting mean and dividing by std  \n",
    "- Applying the same weight across multiple samples  \n",
    "\n",
    "Without broadcasting, we‚Äôd have to manually duplicate data ‚Üí very inefficient.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d33abbdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor + scalar:\n",
      " tensor([[11, 12, 13],\n",
      "        [14, 15, 16]])\n",
      "Tensor + vector:\n",
      " tensor([[101, 202, 303],\n",
      "        [104, 205, 306]])\n"
     ]
    }
   ],
   "source": [
    "tensor_2d = torch.tensor([[1, 2, 3],\n",
    "                          [4, 5, 6]])\n",
    "scalar = 10\n",
    "vector = torch.tensor([100, 200, 300])\n",
    "\n",
    "print(\"Tensor + scalar:\\n\", tensor_2d + scalar)\n",
    "print(\"Tensor + vector:\\n\", tensor_2d + vector)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4cc2fb",
   "metadata": {},
   "source": [
    "## üéØ Part 9: Practice Exercises\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1343dec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores:\n",
      " tensor([[85, 90, 78, 92],\n",
      "        [88, 85, 91, 89],\n",
      "        [79, 95, 87, 93]])\n",
      "Average per student: tensor([86.2500, 88.2500, 88.5000])\n",
      "Average per subject: tensor([84.0000, 90.0000, 85.3333, 91.3333])\n",
      "Highest score: tensor(95)\n",
      "Lowest score: tensor(78)\n"
     ]
    }
   ],
   "source": [
    "# Example: Student scores\n",
    "scores = torch.tensor([[85, 90, 78, 92],\n",
    "                       [88, 85, 91, 89],\n",
    "                       [79, 95, 87, 93]])\n",
    "print(\"Scores:\\n\", scores)\n",
    "\n",
    "print(\"Average per student:\", scores.float().mean(dim=1))\n",
    "print(\"Average per subject:\", scores.float().mean(dim=0))\n",
    "print(\"Highest score:\", scores.max())\n",
    "print(\"Lowest score:\", scores.min())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9afd2723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: torch.Size([32, 32, 3])\n",
      "CHW format: torch.Size([3, 32, 32])\n",
      "Batch images shape: torch.Size([1, 3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "# Example: Image\n",
    "image = torch.randn(32, 32, 3)   # H x W x C\n",
    "print(\"Image shape:\", image.shape)\n",
    "\n",
    "image_chw = image.permute(2, 0, 1)   # Convert to (C, H, W)\n",
    "print(\"CHW format:\", image_chw.shape)\n",
    "\n",
    "batch_images = image_chw.unsqueeze(0)  # Add batch dimension\n",
    "print(\"Batch images shape:\", batch_images.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16915d85",
   "metadata": {},
   "source": [
    "## üìö Summary\n",
    "\n",
    "‚úÖ What we learned:\n",
    "- Tensors = multi-dimensional arrays (foundation of ML)  \n",
    "- How to create tensors (from lists, NumPy, zeros, ones, random, ranges)  \n",
    "- Tensor attributes: shape, dimensions, dtype, device  \n",
    "- Indexing & slicing like NumPy  \n",
    "- Basic operations (+, -, *, /, power)  \n",
    "- Matrix operations (matmul, transpose, sum, mean, min, max)  \n",
    "- Reshape & flatten  \n",
    "- Broadcasting rules  \n",
    "- Real-world practice (scores, images)\n",
    "\n",
    "üöÄ Next Lesson: **Automatic Differentiation (Gradients)**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad86d5e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Learn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

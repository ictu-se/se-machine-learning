{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a330b2dc",
   "metadata": {},
   "source": [
    "# üìò Gradient & Computation Graph Tutorial\n",
    "\n",
    "---\n",
    "\n",
    "### üéØ The rate of change\n",
    "Before using PyTorch to compute gradients automatically, we must understand the **mathematical foundation**.  \n",
    "The gradient is simply the **rate of change**, and it comes from the definition of the **derivative**.\n",
    "\n",
    "---\n",
    "\n",
    "## The true definition of derivative\n",
    "\n",
    "For a function f(x), the derivative at a point \\( x \\) is defined as:\n",
    "\n",
    "$\n",
    "f'(x) = \\lim_{h \\to 0} \\frac{f(x+h) - f(x)}{h}\n",
    "$\n",
    "\n",
    "üëâ This measures the slope of the tangent line to \\( f(x) \\) at point \\( x \\).\n",
    "\n",
    "---\n",
    "\n",
    "### Example: $ f(x) = x^2 $\n",
    "\n",
    "Using the definition:\n",
    "\n",
    "$\n",
    "f'(x) = \\lim_{h \\to 0} \\frac{(x+h)^2 - x^2}{h}\n",
    "$\n",
    "\n",
    "$\n",
    "= \\lim_{h \\to 0} \\frac{x^2 + 2xh + h^2 - x^2}{h}\n",
    "$\n",
    "\n",
    "$\n",
    "= \\lim_{h \\to 0} \\frac{2xh + h^2}{h}\n",
    "= \\lim_{h \\to 0} (2x + h)\n",
    "= 2x\n",
    "$\n",
    "\n",
    "So:\n",
    "\n",
    "$\n",
    "f'(x) = 2x\n",
    "$\n",
    "\n",
    "At \\( x = 3 \\):\n",
    "\n",
    "$\n",
    "f'(3) = 6\n",
    "$\n",
    "\n",
    "---\n",
    "\n",
    "## Newton‚Äôs notation\n",
    "\n",
    "We can write the derivative as $ y' $.  \n",
    "For $y = x^2$:  \n",
    "\n",
    "$\n",
    "y' = 2x\n",
    "$\n",
    "\n",
    "---\n",
    "\n",
    "## Leibniz notation\n",
    "\n",
    "We can also write:\n",
    "\n",
    "$\n",
    "\\frac{dy}{dx} = 2x\n",
    "$\n",
    "\n",
    "üëâ Both notations mean the same thing. Leibniz emphasizes ‚Äúchange in $y$ per change in $x$‚Äù.\n",
    "\n",
    "---\n",
    "\n",
    "## Why this matters in ML?\n",
    "\n",
    "- Derivatives tell us **how sensitive the output is to a small change in the input**.  \n",
    "- In machine learning:\n",
    "  - Input = model parameters (weights, bias).  \n",
    "  - Output = loss function.  \n",
    "- Gradient = tells us **which direction to adjust parameters to reduce loss**.\n",
    "\n",
    "üëâ Gradient descent = follow the slope downhill.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e209f9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function: f(x) = x^2\n",
      "Point: x = 3\n",
      "Derivative (limit approximation) = 6.000001000927568\n",
      "Derivative (exact formula)       = 6\n"
     ]
    }
   ],
   "source": [
    "# Demonstrating derivative using the definition with limit\n",
    "\n",
    "def f(x):\n",
    "    return x**2   # function f(x) = x^2\n",
    "\n",
    "def derivative_limit(f, x, h=1e-6):\n",
    "    return (f(x + h) - f(x)) / h   # finite difference approximation\n",
    "\n",
    "# Pick a point\n",
    "x0 = 3\n",
    "approx = derivative_limit(f, x0)\n",
    "exact = 2 * x0   # we know derivative is 2x\n",
    "\n",
    "print(f\"Function: f(x) = x^2\")\n",
    "print(f\"Point: x = {x0}\")\n",
    "print(f\"Derivative (limit approximation) = {approx}\")\n",
    "print(f\"Derivative (exact formula)       = {exact}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e36f0c",
   "metadata": {},
   "source": [
    "## 1) From Derivative to Gradient\n",
    "\n",
    "So far, we looked at the **derivative** of a function with a single input variable:\n",
    "\n",
    "$\n",
    "f(x) = x^2, \\quad f'(x) = \\frac{dy}{dx} = 2x\n",
    "$\n",
    "\n",
    "üëâ The derivative tells us **how fast the function changes with respect to one variable**.\n",
    "\n",
    "---\n",
    "\n",
    "### What if we have more than one variable?\n",
    "\n",
    "In machine learning, loss functions usually depend on **many parameters** (weights, biases).  \n",
    "For example:\n",
    "\n",
    "$\n",
    "y = (x_1 + x_2) \\cdot x_3\n",
    "$\n",
    "\n",
    "Now, we can‚Äôt just ask ‚Äúwhat is the slope?‚Äù ‚Äî because there are multiple directions to move.  \n",
    "Instead, we compute **partial derivatives**:\n",
    "\n",
    "$\n",
    "\\frac{\\partial y}{\\partial x_1} = x_3, \\quad\n",
    "\\frac{\\partial y}{\\partial x_2} = x_3, \\quad\n",
    "\\frac{\\partial y}{\\partial x_3} = (x_1 + x_2)\n",
    "$\n",
    "\n",
    "---\n",
    "\n",
    "### The Gradient\n",
    "\n",
    "The collection of all partial derivatives is called the **gradient**:\n",
    "\n",
    "$\n",
    "\\nabla y = \n",
    "\\begin{bmatrix}\n",
    "\\frac{\\partial y}{\\partial x_1} \\\\\n",
    "\\frac{\\partial y}{\\partial x_2} \\\\\n",
    "\\frac{\\partial y}{\\partial x_3}\n",
    "\\end{bmatrix}\n",
    "$\n",
    "\n",
    "üëâ The gradient is a **vector** that points in the direction of the steepest increase of the function.  \n",
    "\n",
    "In machine learning, we use the **negative gradient** (steepest descent) to update parameters and reduce loss.\n",
    "\n",
    "---\n",
    "\n",
    "### Intuition\n",
    "\n",
    "- **Derivative** = slope in 1D.  \n",
    "- **Gradient** = slope vector in multi-dimensional space.  \n",
    "\n",
    "This is why PyTorch computes gradients for every parameter at once ‚Äî so we can update all weights together during training.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bfc6d44",
   "metadata": {},
   "source": [
    "# üìò Gradient & Computation Graph Tutorial\n",
    "\n",
    "---\n",
    "\n",
    "### üéØ Why this tutorial matters\n",
    "- Every deep learning model is trained with **gradient descent**.  \n",
    "- Gradients are computed automatically by **backpropagation**.  \n",
    "- Backprop relies on a **computation graph** (a directed acyclic graph of operations).  \n",
    "\n",
    "üëâ In this tutorial, we will:\n",
    "1. Compute gradients with PyTorch.  \n",
    "2. Visualize the computation graph with `graphviz.Digraph`.  \n",
    "3. See *why* backprop works step by step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c71bc02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from graphviz import Digraph\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88a2000",
   "metadata": {},
   "source": [
    "## 1) Why do we need gradients?\n",
    "\n",
    "- Training = finding the best parameters (weights, bias).  \n",
    "- We measure error using a **loss function**.  \n",
    "- Gradients tell us:\n",
    "  - Which direction to move parameters.  \n",
    "  - How big the change should be.  \n",
    "\n",
    "üëâ Without gradients, we cannot update weights automatically.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "766038cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output y = 20.0\n"
     ]
    }
   ],
   "source": [
    "# Example: simple function y = (x1 + x2) * x3\n",
    "x1 = torch.tensor(2.0, requires_grad=True)\n",
    "x2 = torch.tensor(3.0, requires_grad=True)\n",
    "x3 = torch.tensor(4.0, requires_grad=True)\n",
    "\n",
    "y = (x1 + x2) * x3\n",
    "print(\"Output y =\", y.item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd17933",
   "metadata": {},
   "source": [
    "## 2) Backpropagation in action\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8c732f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dy/dx1 = 4.0\n",
      "dy/dx2 = 4.0\n",
      "dy/dx3 = 5.0\n"
     ]
    }
   ],
   "source": [
    "y.backward()\n",
    "\n",
    "print(\"dy/dx1 =\", x1.grad.item())\n",
    "print(\"dy/dx2 =\", x2.grad.item())\n",
    "print(\"dy/dx3 =\", x3.grad.item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4b447c",
   "metadata": {},
   "source": [
    "### WHY these values?\n",
    "\n",
    "Function:  \n",
    "$\n",
    "y = (x_1 + x_2) \\cdot x_3\n",
    "$\n",
    "\n",
    "Derivatives:  \n",
    "- dy/dx1 = x3 = 4  \n",
    "- dy/dx2 = x3 = 4  \n",
    "- dy/dx3 = (x1 + x2) = 5  \n",
    "\n",
    "üëâ PyTorch gives the same result!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66696327",
   "metadata": {},
   "source": [
    "## 3) Drawing the Computation Graph\n",
    "\n",
    "We‚Äôll use `graphviz.Digraph` to visualize how `y` is built from inputs.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f67db5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 13.1.2 (20250808.2320)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"327pt\" height=\"174pt\"\n",
       " viewBox=\"0.00 0.00 327.00 174.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 169.73)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-169.73 323.47,-169.73 323.47,4 -4,4\"/>\n",
       "<!-- x1 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>x1</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"30.37\" cy=\"-135.37\" rx=\"30.37\" ry=\"30.37\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"30.37\" y=\"-130.32\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">x1=2</text>\n",
       "</g>\n",
       "<!-- add -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>add</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"154.1,-114.37 100.1,-114.37 100.1,-78.37 154.1,-78.37 154.1,-114.37\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"127.1\" y=\"-91.32\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">+</text>\n",
       "</g>\n",
       "<!-- x1&#45;&gt;add -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>x1&#45;&gt;add</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M59.02,-123.98C68.49,-120.09 79.23,-115.66 89.3,-111.52\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"90.56,-114.78 98.48,-107.74 87.9,-108.31 90.56,-114.78\"/>\n",
       "</g>\n",
       "<!-- x2 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>x2</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"30.37\" cy=\"-56.37\" rx=\"30.37\" ry=\"30.37\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"30.37\" y=\"-51.32\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">x2=3</text>\n",
       "</g>\n",
       "<!-- x2&#45;&gt;add -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>x2&#45;&gt;add</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M58.77,-67.94C68.34,-71.98 79.24,-76.58 89.45,-80.89\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"87.77,-83.98 98.35,-84.65 90.5,-77.53 87.77,-83.98\"/>\n",
       "</g>\n",
       "<!-- x3 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>x3</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"127.1\" cy=\"-30.37\" rx=\"30.37\" ry=\"30.37\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"127.1\" y=\"-25.32\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">x3=4</text>\n",
       "</g>\n",
       "<!-- mul -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>mul</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"247.47,-81.37 193.47,-81.37 193.47,-45.37 247.47,-45.37 247.47,-81.37\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"220.47\" y=\"-58.32\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">*</text>\n",
       "</g>\n",
       "<!-- x3&#45;&gt;mul -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>x3&#45;&gt;mul</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M156.01,-40.45C164.28,-43.43 173.46,-46.75 182.22,-49.91\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"180.96,-53.18 191.56,-53.29 183.34,-46.6 180.96,-53.18\"/>\n",
       "</g>\n",
       "<!-- add&#45;&gt;mul -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>add&#45;&gt;mul</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M154.53,-86.82C163.24,-83.68 173.1,-80.12 182.45,-76.74\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"183.46,-80.09 191.68,-73.4 181.08,-73.51 183.46,-80.09\"/>\n",
       "</g>\n",
       "<!-- y -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>y</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"301.47\" cy=\"-63.37\" rx=\"18\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"301.47\" y=\"-58.32\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">y</text>\n",
       "</g>\n",
       "<!-- mul&#45;&gt;y -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>mul&#45;&gt;y</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M247.77,-63.37C255.52,-63.37 264.04,-63.37 271.92,-63.37\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"271.71,-66.87 281.71,-63.37 271.71,-59.87 271.71,-66.87\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x14e250efef0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dot = Digraph(format=\"png\", graph_attr={\"rankdir\": \"LR\"})\n",
    "def draw_graph():\n",
    "    \n",
    "\n",
    "    # Nodes\n",
    "    dot.node(\"x1\", \"x1=2\", shape=\"circle\")\n",
    "    dot.node(\"x2\", \"x2=3\", shape=\"circle\")\n",
    "    dot.node(\"x3\", \"x3=4\", shape=\"circle\")\n",
    "    dot.node(\"add\", \"+\", shape=\"box\")\n",
    "    dot.node(\"mul\", \"*\", shape=\"box\")\n",
    "    dot.node(\"y\", \"y\", shape=\"circle\")\n",
    "\n",
    "    # Edges\n",
    "    dot.edge(\"x1\", \"add\")\n",
    "    dot.edge(\"x2\", \"add\")\n",
    "    dot.edge(\"add\", \"mul\")\n",
    "    dot.edge(\"x3\", \"mul\")\n",
    "    dot.edge(\"mul\", \"y\")\n",
    "\n",
    "    return dot\n",
    "\n",
    "dot = draw_graph()\n",
    "dot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e46e81f",
   "metadata": {},
   "source": [
    "## ‚úÖ Summary\n",
    "\n",
    "- Gradients = how parameters should change to reduce loss.  \n",
    "- Computation graph = roadmap of operations for backprop.  \n",
    "- PyTorch builds this graph dynamically ‚Üí no need to do calculus manually.  \n",
    "- Deep learning = giant computation graphs with millions of nodes.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e5496e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda128",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
